
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{hw5}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \section{Computer Vision}\label{computer-vision}

\section{Jacobs University Bremen}\label{jacobs-university-bremen}

\section{Fall 2020}\label{fall-2020}

\section{Homework 5}\label{homework-5}

\emph{This notebook includes both coding and written questions. Please
hand in this notebook file with all the outputs and your answers to the
written questions.}

This assignment covers K-Means and HAC methods for clustering and image
segmentation.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}1}]:} \PY{c+c1}{\PYZsh{} Setup}
        \PY{k+kn}{from} \PY{n+nn}{\PYZus{}\PYZus{}future\PYZus{}\PYZus{}} \PY{k}{import} \PY{n}{print\PYZus{}function}
        \PY{k+kn}{from} \PY{n+nn}{time} \PY{k}{import} \PY{n}{time}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
        \PY{k+kn}{from} \PY{n+nn}{matplotlib} \PY{k}{import} \PY{n}{rc}
        \PY{k+kn}{from} \PY{n+nn}{skimage} \PY{k}{import} \PY{n}{io}
        
        
        \PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
        \PY{n}{plt}\PY{o}{.}\PY{n}{rcParams}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{figure.figsize}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{p}{(}\PY{l+m+mf}{15.0}\PY{p}{,} \PY{l+m+mf}{12.0}\PY{p}{)} \PY{c+c1}{\PYZsh{} set default size of plots}
        \PY{n}{plt}\PY{o}{.}\PY{n}{rcParams}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{image.interpolation}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{nearest}\PY{l+s+s1}{\PYZsq{}}
        \PY{n}{plt}\PY{o}{.}\PY{n}{rcParams}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{image.cmap}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gray}\PY{l+s+s1}{\PYZsq{}}
        
        \PY{c+c1}{\PYZsh{} for auto\PYZhy{}reloading extenrnal modules}
        \PY{o}{\PYZpc{}}\PY{k}{load\PYZus{}ext} autoreload
        \PY{o}{\PYZpc{}}\PY{k}{autoreload} 2
\end{Verbatim}


    \subsection{Introduction}\label{introduction}

In this assignment, you will use clustering algorithms to segment
images. You will then use these segmentations to identify foreground and
background objects.

Your assignment will involve the following subtasks: -
\textbf{Clustering algorithms}: Implement K-Means clustering and
Hierarchical Agglomerative Clustering. - \textbf{Pixel-level features}:
Implement a feature vector that combines color and position information
and implement feature normalization. - \textbf{Quantitative Evaluation}:
Evaluate segmentation algorithms with a variety of parameter settings by
comparing your computed segmentations against a dataset of ground-truth
segmentations.

    \subsection{1 Clustering Algorithms (40
points)}\label{clustering-algorithms-40-points}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}2}]:} \PY{c+c1}{\PYZsh{} Generate random data points for clustering}
        
        \PY{c+c1}{\PYZsh{} Set seed for consistency}
        \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Cluster 1}
        \PY{n}{mean1} \PY{o}{=} \PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}
        \PY{n}{cov1} \PY{o}{=} \PY{p}{[}\PY{p}{[}\PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mf}{0.1}\PY{p}{]}\PY{p}{]}
        \PY{n}{X1} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{multivariate\PYZus{}normal}\PY{p}{(}\PY{n}{mean1}\PY{p}{,} \PY{n}{cov1}\PY{p}{,} \PY{l+m+mi}{100}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Cluster 2}
        \PY{n}{mean2} \PY{o}{=} \PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}
        \PY{n}{cov2} \PY{o}{=} \PY{p}{[}\PY{p}{[}\PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mf}{0.1}\PY{p}{]}\PY{p}{]}
        \PY{n}{X2} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{multivariate\PYZus{}normal}\PY{p}{(}\PY{n}{mean2}\PY{p}{,} \PY{n}{cov2}\PY{p}{,} \PY{l+m+mi}{100}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Cluster 3}
        \PY{n}{mean3} \PY{o}{=} \PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}
        \PY{n}{cov3} \PY{o}{=} \PY{p}{[}\PY{p}{[}\PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mf}{0.1}\PY{p}{]}\PY{p}{]}
        \PY{n}{X3} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{multivariate\PYZus{}normal}\PY{p}{(}\PY{n}{mean3}\PY{p}{,} \PY{n}{cov3}\PY{p}{,} \PY{l+m+mi}{100}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Cluster 4}
        \PY{n}{mean4} \PY{o}{=} \PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}
        \PY{n}{cov4} \PY{o}{=} \PY{p}{[}\PY{p}{[}\PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mf}{0.1}\PY{p}{]}\PY{p}{]}
        \PY{n}{X4} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{multivariate\PYZus{}normal}\PY{p}{(}\PY{n}{mean4}\PY{p}{,} \PY{n}{cov4}\PY{p}{,} \PY{l+m+mi}{100}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Merge two sets of data points}
        \PY{n}{X} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{concatenate}\PY{p}{(}\PY{p}{(}\PY{n}{X1}\PY{p}{,} \PY{n}{X2}\PY{p}{,} \PY{n}{X3}\PY{p}{,} \PY{n}{X4}\PY{p}{)}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Plot data points}
        \PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{X}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{X}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{equal}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_4_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection{1.1 K-Means Clustering (20
points)}\label{k-means-clustering-20-points}

As discussed in class, K-Means is one of the most popular clustering
algorithms. We have provided skeleton code for K-Means clustering in the
file \texttt{segmentation.py}. Your first task is to finish implementing
\textbf{\texttt{kmeans}} in \texttt{segmentation.py}. This version uses
nested for loops to assign points to the closest centroid and compute a
new mean for each cluster.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{k+kn}{from} \PY{n+nn}{segmentation} \PY{k}{import} \PY{n}{kmeans}
        
        \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}
        \PY{n}{start} \PY{o}{=} \PY{n}{time}\PY{p}{(}\PY{p}{)}
        \PY{n}{assignments} \PY{o}{=} \PY{n}{kmeans}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{)}
        \PY{n}{end} \PY{o}{=} \PY{n}{time}\PY{p}{(}\PY{p}{)}
        
        \PY{n}{kmeans\PYZus{}runtime} \PY{o}{=} \PY{n}{end} \PY{o}{\PYZhy{}} \PY{n}{start}
        
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{kmeans running time: }\PY{l+s+si}{\PYZpc{}f}\PY{l+s+s2}{ seconds.}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{n}{kmeans\PYZus{}runtime}\PY{p}{)}
        
        \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{4}\PY{p}{)}\PY{p}{:}
            \PY{n}{cluster\PYZus{}i} \PY{o}{=} \PY{n}{X}\PY{p}{[}\PY{n}{assignments}\PY{o}{==}\PY{n}{i}\PY{p}{]}
            \PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{cluster\PYZus{}i}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{cluster\PYZus{}i}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}
        
        \PY{n}{plt}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{equal}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
kmeans running time: 0.392223 seconds.

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_6_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    We can use numpy functions and broadcasting to make K-Means faster.
Implement \textbf{\texttt{kmeans\_fast}} in \texttt{segmentation.py}.
This should run at least 10 times faster than the previous
implementation.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{k+kn}{from} \PY{n+nn}{segmentation} \PY{k}{import} \PY{n}{kmeans\PYZus{}fast}
        
        \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}
        \PY{n}{start} \PY{o}{=} \PY{n}{time}\PY{p}{(}\PY{p}{)}
        \PY{n}{assignments} \PY{o}{=} \PY{n}{kmeans\PYZus{}fast}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{)}
        \PY{n}{end} \PY{o}{=} \PY{n}{time}\PY{p}{(}\PY{p}{)}
        
        \PY{n}{kmeans\PYZus{}fast\PYZus{}runtime} \PY{o}{=} \PY{n}{end} \PY{o}{\PYZhy{}} \PY{n}{start}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{kmeans running time: }\PY{l+s+si}{\PYZpc{}f}\PY{l+s+s2}{ seconds.}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{n}{kmeans\PYZus{}fast\PYZus{}runtime}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+si}{\PYZpc{}f}\PY{l+s+s2}{ times faster!}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{p}{(}\PY{n}{kmeans\PYZus{}runtime} \PY{o}{/} \PY{n}{kmeans\PYZus{}fast\PYZus{}runtime}\PY{p}{)}\PY{p}{)}
        
        \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{4}\PY{p}{)}\PY{p}{:}
            \PY{n}{cluster\PYZus{}i} \PY{o}{=} \PY{n}{X}\PY{p}{[}\PY{n}{assignments}\PY{o}{==}\PY{n}{i}\PY{p}{]}
            \PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{cluster\PYZus{}i}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{cluster\PYZus{}i}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}
        
        \PY{n}{plt}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{equal}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
kmeans running time: 0.017731 seconds.
22.121087 times faster!

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_8_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection{1.2 K-Means Convergence (10
points)}\label{k-means-convergence-10-points}

Implementations of the K-Means algorithm will often have the parameter
\texttt{num\_iters} to define the maximum number of iterations the
algorithm should run for. Consider that we opt to not include this upper
bound on the number of iterations, and that we define the termination
criterion of the algorithm to be when the cost \(L\) stops changing.

Recall that \(L\) is defined as the sum of squared distance between all
points \(x\) and their nearest cluster center \(c\):

\[L = \sum_{i \in clusters}\sum_{x \in cluster_i} (x - c_i)^2\]

Show that for any set of points \textbf{\(D\)} and any number of
clusters \(k\), the K-Means algorithm will terminate in a finite number
of iterations.

    \textbf{Your answer here:}

There are only a finiite number of possible cluster assignments. For
example, if we have D data points and we need to assign them in K
clusters, the max possible number of assignments is K\^{}D. For each
iteration of the algorithm, we produce a new clustering based only on
the old clustering. There are two things to consider:

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  If the old clustering is the same as the new, then the next clustering
  will again be the same.
\item
  If the new clustering is different from the old then the newer one has
  a lower cost.
\end{enumerate}

The domain for k-means is a finite set. So, the iteration will
eventually enter a cycle. This cycle can not have a length greater than
1 because otherwise by (b), we will end up with a clustering that has a
lower cost than itself which is impossible. This is impossible because
any reasonable K-means algorithm will strictly reduce the error on each
step, so you could not possibly come back to the same assignment.

Thus, the cycle must have length exactly 1. Hence k-means converges in a
finite number of iterations.

References:

https://stats.stackexchange.com/questions/181319/why-k-means-algorithm-will-terminate-in-a-finite-number-of-iterations

https://stats.stackexchange.com/questions/188087/proof-of-convergence-of-k-means

    \subsubsection{1.2 Hierarchical Agglomerative Clustering (10
points)}\label{hierarchical-agglomerative-clustering-10-points}

Another simple clustering algorithm is Hieararchical Agglomerative
Clustering, which is somtimes abbreviated as HAC. In this algorithm,
each point is initially assigned to its own cluster. Then cluster pairs
are merged until we are left with the desired number of predetermined
clusters (see Algorithm 1).

Implement \textbf{\texttt{hiererachical\_clustering}} in
\texttt{segmentation.py}.

\begin{figure}
\centering
\includegraphics{attachment:algo1.png}
\caption{algo1.png}
\end{figure}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} \PY{k+kn}{from} \PY{n+nn}{segmentation} \PY{k}{import} \PY{n}{hierarchical\PYZus{}clustering}
        
        \PY{n}{start} \PY{o}{=} \PY{n}{time}\PY{p}{(}\PY{p}{)}
        \PY{n}{assignments} \PY{o}{=} \PY{n}{hierarchical\PYZus{}clustering}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{)}
        \PY{n}{end} \PY{o}{=} \PY{n}{time}\PY{p}{(}\PY{p}{)}
        
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{hierarchical\PYZus{}clustering running time: }\PY{l+s+si}{\PYZpc{}f}\PY{l+s+s2}{ seconds.}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{p}{(}\PY{n}{end} \PY{o}{\PYZhy{}} \PY{n}{start}\PY{p}{)}\PY{p}{)}
        
        \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{4}\PY{p}{)}\PY{p}{:}
            \PY{n}{cluster\PYZus{}i} \PY{o}{=} \PY{n}{X}\PY{p}{[}\PY{n}{assignments}\PY{o}{==}\PY{n}{i}\PY{p}{]}
            \PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{cluster\PYZus{}i}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{cluster\PYZus{}i}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}
        
        \PY{n}{plt}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{equal}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
hierarchical\_clustering running time: 0.197994 seconds.

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_12_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsection{2 Pixel-Level Features (30
points)}\label{pixel-level-features-30-points}

Before we can use a clustering algorithm to segment an image, we must
compute some \emph{feature vector} for each pixel. The feature vector
for each pixel should encode the qualities that we care about in a good
segmentation. More concretely, for a pair of pixels \(p_i\) and \(p_j\)
with corresponding feature vectors \(f_i\) and \(f_j\), the distance
between \(f_i\) and \(f_j\) should be small if we believe that \(p_i\)
and \(p_j\) should be placed in the same segment and large otherwise.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}6}]:} \PY{c+c1}{\PYZsh{} Load and display image}
        \PY{n}{img} \PY{o}{=} \PY{n}{io}\PY{o}{.}\PY{n}{imread}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train.jpg}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{H}\PY{p}{,} \PY{n}{W}\PY{p}{,} \PY{n}{C} \PY{o}{=} \PY{n}{img}\PY{o}{.}\PY{n}{shape}
        
        \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{img}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{off}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_14_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection{2.1 Color Features (15
points)}\label{color-features-15-points}

One of the simplest possible feature vectors for a pixel is simply the
vector of colors for that pixel. Implement
\textbf{\texttt{color\_features}} in \texttt{segmentation.py}. Output
should look like the following:
\includegraphics{attachment:color_features.png}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{k+kn}{from} \PY{n+nn}{segmentation} \PY{k}{import} \PY{n}{color\PYZus{}features}
        \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}
        
        \PY{n}{features} \PY{o}{=} \PY{n}{color\PYZus{}features}\PY{p}{(}\PY{n}{img}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Sanity checks}
        \PY{k}{assert} \PY{n}{features}\PY{o}{.}\PY{n}{shape} \PY{o}{==} \PY{p}{(}\PY{n}{H} \PY{o}{*} \PY{n}{W}\PY{p}{,} \PY{n}{C}\PY{p}{)}\PY{p}{,}\PYZbs{}
            \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Incorrect shape! Check your implementation.}\PY{l+s+s2}{\PYZdq{}}
        
        \PY{k}{assert} \PY{n}{features}\PY{o}{.}\PY{n}{dtype} \PY{o}{==} \PY{n}{np}\PY{o}{.}\PY{n}{float}\PY{p}{,}\PYZbs{}
            \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{dtype of color\PYZus{}features should be float.}\PY{l+s+s2}{\PYZdq{}}
        
        \PY{n}{assignments} \PY{o}{=} \PY{n}{kmeans\PYZus{}fast}\PY{p}{(}\PY{n}{features}\PY{p}{,} \PY{l+m+mi}{8}\PY{p}{)}
        \PY{n}{segments} \PY{o}{=} \PY{n}{assignments}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{p}{(}\PY{n}{H}\PY{p}{,} \PY{n}{W}\PY{p}{)}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Display segmentation}
        \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{segments}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{viridis}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{off}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_16_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    In the cell below, we visualize each segment as the mean color of pixels
in the segment.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}8}]:} \PY{k+kn}{from} \PY{n+nn}{utils} \PY{k}{import} \PY{n}{visualize\PYZus{}mean\PYZus{}color\PYZus{}image}
        \PY{n}{visualize\PYZus{}mean\PYZus{}color\PYZus{}image}\PY{p}{(}\PY{n}{img}\PY{p}{,} \PY{n}{segments}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_18_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection{2.2 Color and Position Features (15
points)}\label{color-and-position-features-15-points}

Another simple feature vector for a pixel is to concatenate its color
and position within the image. In other words, for a pixel of color
\((r, g, b)\) located at position \((x, y)\) in the image, its feature
vector would be \((r, g, b, x, y)\). However, the color and position
features may have drastically different ranges; for example each color
channel of an image may be in the range \([0, 1)\), while the position
of each pixel may have a much wider range. Uneven scaling between
different features in the feature vector may cause clustering algorithms
to behave poorly.

One way to correct for uneven scaling between different features is to
apply some sort of normalization to the feature vector. One of the
simplest types of normalization is to force each feature to have zero
mean and unit variance.

Implement \textbf{\texttt{color\_position\_features}} in
\texttt{segmentation.py}.

Output segmentation should look like the following:
\includegraphics{attachment:color_position_features.png}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}9}]:} \PY{k+kn}{from} \PY{n+nn}{segmentation} \PY{k}{import} \PY{n}{color\PYZus{}position\PYZus{}features}
        \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}
        
        \PY{n}{features} \PY{o}{=} \PY{n}{color\PYZus{}position\PYZus{}features}\PY{p}{(}\PY{n}{img}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Sanity checks}
        \PY{k}{assert} \PY{n}{features}\PY{o}{.}\PY{n}{shape} \PY{o}{==} \PY{p}{(}\PY{n}{H} \PY{o}{*} \PY{n}{W}\PY{p}{,} \PY{n}{C} \PY{o}{+} \PY{l+m+mi}{2}\PY{p}{)}\PY{p}{,}\PYZbs{}
            \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Incorrect shape! Check your implementation.}\PY{l+s+s2}{\PYZdq{}}
        
        \PY{k}{assert} \PY{n}{features}\PY{o}{.}\PY{n}{dtype} \PY{o}{==} \PY{n}{np}\PY{o}{.}\PY{n}{float}\PY{p}{,}\PYZbs{}
            \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{dtype of color\PYZus{}features should be float.}\PY{l+s+s2}{\PYZdq{}}
        
        \PY{n}{assignments} \PY{o}{=} \PY{n}{kmeans\PYZus{}fast}\PY{p}{(}\PY{n}{features}\PY{p}{,} \PY{l+m+mi}{8}\PY{p}{)}
        
        \PY{n}{segments} \PY{o}{=} \PY{n}{assignments}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{p}{(}\PY{n}{H}\PY{p}{,} \PY{n}{W}\PY{p}{)}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Display segmentation}
        \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{segments}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{viridis}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{off}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_20_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}10}]:} \PY{n}{visualize\PYZus{}mean\PYZus{}color\PYZus{}image}\PY{p}{(}\PY{n}{img}\PY{p}{,} \PY{n}{segments}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_21_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection{Extra Credit: Implement Your Own
Feature}\label{extra-credit-implement-your-own-feature}

For this programming assignment we have asked you to implement a very
simple feature transform for each pixel. While it is not required, you
should feel free to experiment with other feature transforms. Could your
final segmentations be improved by adding gradients, edges, SIFT
descriptors, or other information to your feature vectors? Could a
different type of normalization give better results?

Implement your feature extractor \textbf{\texttt{my\_features}} in
\texttt{segmentation.py}

Depending on the creativity of your approach and the quality of your
writeup, implementing extra feature vectors can be worth extra credit
(up to 1 point).

    \textbf{Describe your approach}: I have extracted horizontal edge
features here using the x-direction Prewitt kernel. An edge is basically
where there is a sharp change in color. This can be detected by
observing changes in pixel values in image matrices.

If we have an image matrix, we consider one pixel value at a time. To
identify if a pixel is an edge or not, we will simply subtract the
values on either side of the pixel. For example, if our selected pixel
has a value of 85, and the values on its sides are 89 and 78, we
subtract values and see the differences. Since this differences aren't
very large, we can say that there is no edge around this pixel.

To extract edges, other the Sobel kernel could also be used.

Reference:
https://www.analyticsvidhya.com/blog/2019/08/3-techniques-extract-features-from-image-data-machine-learning-python/

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}11}]:} \PY{c+c1}{\PYZsh{} PENDING}
         \PY{k+kn}{from} \PY{n+nn}{segmentation} \PY{k}{import} \PY{n}{my\PYZus{}features}
         \PY{k+kn}{from} \PY{n+nn}{segmentation} \PY{k}{import} \PY{n}{kmeans\PYZus{}fast}
         
         \PY{c+c1}{\PYZsh{} Feel free to experiment with different images}
         \PY{c+c1}{\PYZsh{} and varying number of segments}
         \PY{n}{img} \PY{o}{=} \PY{n}{io}\PY{o}{.}\PY{n}{imread}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train.jpg}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{num\PYZus{}segments} \PY{o}{=} \PY{l+m+mi}{8}
         
         \PY{n}{H}\PY{p}{,} \PY{n}{W}\PY{p}{,} \PY{n}{C} \PY{o}{=} \PY{n}{img}\PY{o}{.}\PY{n}{shape}
         
         \PY{c+c1}{\PYZsh{} Extract pixel\PYZhy{}level features}
         \PY{n}{features} \PY{o}{=} \PY{n}{my\PYZus{}features}\PY{p}{(}\PY{n}{img}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Run clustering algorithm}
         
         \PY{n}{assignments} \PY{o}{=} \PY{n}{kmeans\PYZus{}fast}\PY{p}{(}\PY{n}{features}\PY{p}{,} \PY{n}{num\PYZus{}segments}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{}segments = assignments.reshape((H, W))}
         
         \PY{c+c1}{\PYZsh{} Display segmentation}
         \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{features}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gray}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{off}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_24_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsection{3 Quantitative Evaluation (30
points)}\label{quantitative-evaluation-30-points}

Looking at images is a good way to get an idea for how well an algorithm
is working, but the best way to evaluate an algorithm is to have some
quantitative measure of its performance.

For this project we have supplied a small dataset of cat images and
ground truth segmentations of these images into foreground (cats) and
background (everything else). We will quantitatively evaluate different
segmentation methods (features and clustering methods) on this dataset.

We can cast the segmentation task into a binary classification problem,
where we need to classify each pixel in an image into either foreground
(positive) or background (negative). Given the ground-truth labels, the
accuracy of a segmentation is \((TP+TN)/(P+N)\).

Implement \textbf{\texttt{compute\_accuracy}} in
\texttt{segmentation.py}.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}12}]:} \PY{k+kn}{from} \PY{n+nn}{segmentation} \PY{k}{import} \PY{n}{compute\PYZus{}accuracy}
         
         \PY{n}{mask\PYZus{}gt} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{p}{(}\PY{l+m+mi}{100}\PY{p}{,} \PY{l+m+mi}{100}\PY{p}{)}\PY{p}{)}
         \PY{n}{mask} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{p}{(}\PY{l+m+mi}{100}\PY{p}{,} \PY{l+m+mi}{100}\PY{p}{)}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Test compute\PYZus{}accracy function}
         \PY{n}{mask\PYZus{}gt}\PY{p}{[}\PY{l+m+mi}{20}\PY{p}{:}\PY{l+m+mi}{50}\PY{p}{,} \PY{l+m+mi}{30}\PY{p}{:}\PY{l+m+mi}{60}\PY{p}{]} \PY{o}{=} \PY{l+m+mi}{1}
         \PY{n}{mask}\PY{p}{[}\PY{l+m+mi}{30}\PY{p}{:}\PY{l+m+mi}{50}\PY{p}{,} \PY{l+m+mi}{30}\PY{p}{:}\PY{l+m+mi}{60}\PY{p}{]} \PY{o}{=} \PY{l+m+mi}{1}
         
         \PY{n}{accuracy} \PY{o}{=} \PY{n}{compute\PYZus{}accuracy}\PY{p}{(}\PY{n}{mask\PYZus{}gt}\PY{p}{,} \PY{n}{mask}\PY{p}{)}
         
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Accuracy: }\PY{l+s+si}{\PYZpc{}0.2f}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}} \PY{p}{(}\PY{n}{accuracy}\PY{p}{)}\PY{p}{)}
         \PY{k}{if} \PY{n}{accuracy} \PY{o}{!=} \PY{l+m+mf}{0.97}\PY{p}{:}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Check your implementation!}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{121}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{mask\PYZus{}gt}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Ground Truth}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{off}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{122}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{mask}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Estimate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{off}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Accuracy: 0.97

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_26_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    You can use the script below to evaluate a segmentation method's ability
to separate foreground from background on the entire provided dataset.
Use this script as a starting point to evaluate a variety of
segmentation parameters.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}13}]:} \PY{k+kn}{from} \PY{n+nn}{utils} \PY{k}{import} \PY{n}{load\PYZus{}dataset}\PY{p}{,} \PY{n}{compute\PYZus{}segmentation}
         \PY{k+kn}{from} \PY{n+nn}{segmentation} \PY{k}{import} \PY{n}{evaluate\PYZus{}segmentation}
         
         \PY{c+c1}{\PYZsh{} Load a small segmentation dataset}
         \PY{n}{imgs}\PY{p}{,} \PY{n}{gt\PYZus{}masks} \PY{o}{=} \PY{n}{load\PYZus{}dataset}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Set the parameters for segmentation.}
         \PY{n}{num\PYZus{}segments} \PY{o}{=} \PY{l+m+mi}{3}
         \PY{n}{clustering\PYZus{}fn} \PY{o}{=} \PY{n}{kmeans\PYZus{}fast}
         \PY{n}{feature\PYZus{}fn} \PY{o}{=} \PY{n}{color\PYZus{}features}
         \PY{n}{scale} \PY{o}{=} \PY{l+m+mf}{0.5}
         
         \PY{n}{mean\PYZus{}accuracy} \PY{o}{=} \PY{l+m+mf}{0.0}
         
         \PY{n}{segmentations} \PY{o}{=} \PY{p}{[}\PY{p}{]}
         
         \PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{p}{(}\PY{n}{img}\PY{p}{,} \PY{n}{gt\PYZus{}mask}\PY{p}{)} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n+nb}{zip}\PY{p}{(}\PY{n}{imgs}\PY{p}{,} \PY{n}{gt\PYZus{}masks}\PY{p}{)}\PY{p}{)}\PY{p}{:}
             \PY{c+c1}{\PYZsh{} Compute a segmentation for this image}
             \PY{n}{segments} \PY{o}{=} \PY{n}{compute\PYZus{}segmentation}\PY{p}{(}\PY{n}{img}\PY{p}{,} \PY{n}{num\PYZus{}segments}\PY{p}{,}
                                             \PY{n}{clustering\PYZus{}fn}\PY{o}{=}\PY{n}{clustering\PYZus{}fn}\PY{p}{,}
                                             \PY{n}{feature\PYZus{}fn}\PY{o}{=}\PY{n}{feature\PYZus{}fn}\PY{p}{,}
                                             \PY{n}{scale}\PY{o}{=}\PY{n}{scale}\PY{p}{)}
             
             \PY{n}{segmentations}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{segments}\PY{p}{)}
             
             \PY{c+c1}{\PYZsh{} Evaluate segmentation}
             \PY{n}{accuracy} \PY{o}{=} \PY{n}{evaluate\PYZus{}segmentation}\PY{p}{(}\PY{n}{gt\PYZus{}mask}\PY{p}{,} \PY{n}{segments}\PY{p}{)}
             
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Accuracy for image }\PY{l+s+si}{\PYZpc{}d}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZpc{}0.4f}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}}\PY{p}{(}\PY{n}{i}\PY{p}{,} \PY{n}{accuracy}\PY{p}{)}\PY{p}{)}
             \PY{n}{mean\PYZus{}accuracy} \PY{o}{+}\PY{o}{=} \PY{n}{accuracy}
             
         \PY{n}{mean\PYZus{}accuracy} \PY{o}{=} \PY{n}{mean\PYZus{}accuracy} \PY{o}{/} \PY{n+nb}{len}\PY{p}{(}\PY{n}{imgs}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Mean accuracy: }\PY{l+s+si}{\PYZpc{}0.4f}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}} \PY{n}{mean\PYZus{}accuracy}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Accuracy for image 0: 0.8063
Accuracy for image 1: 0.9583
Accuracy for image 2: 0.9860
Accuracy for image 3: 0.9059
Accuracy for image 4: 0.9575
Accuracy for image 5: 0.6814
Accuracy for image 6: 0.6726
Accuracy for image 7: 0.6726
Accuracy for image 8: 0.8411
Accuracy for image 9: 0.9004
Accuracy for image 10: 0.8552
Accuracy for image 11: 0.8076
Accuracy for image 12: 0.7349
Accuracy for image 13: 0.6511
Accuracy for image 14: 0.7487
Accuracy for image 15: 0.4925
Mean accuracy: 0.7920

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}14}]:} \PY{c+c1}{\PYZsh{} Visualize segmentation results}
         
         \PY{n}{N} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{imgs}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{15}\PY{p}{,}\PY{l+m+mi}{60}\PY{p}{)}\PY{p}{)}
         \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{N}\PY{p}{)}\PY{p}{:}
         
             \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{n}{N}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{,} \PY{p}{(}\PY{n}{i} \PY{o}{*} \PY{l+m+mi}{3}\PY{p}{)} \PY{o}{+} \PY{l+m+mi}{1}\PY{p}{)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{imgs}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{off}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
             \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{n}{N}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{,} \PY{p}{(}\PY{n}{i} \PY{o}{*} \PY{l+m+mi}{3}\PY{p}{)} \PY{o}{+} \PY{l+m+mi}{2}\PY{p}{)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{gt\PYZus{}masks}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{off}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
             \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{n}{N}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{,} \PY{p}{(}\PY{n}{i} \PY{o}{*} \PY{l+m+mi}{3}\PY{p}{)} \PY{o}{+} \PY{l+m+mi}{3}\PY{p}{)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{segmentations}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{viridis}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{off}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_29_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}15}]:} \PY{k+kn}{from} \PY{n+nn}{utils} \PY{k}{import} \PY{n}{load\PYZus{}dataset}\PY{p}{,} \PY{n}{compute\PYZus{}segmentation}
         \PY{k+kn}{from} \PY{n+nn}{segmentation} \PY{k}{import} \PY{n}{evaluate\PYZus{}segmentation}
         \PY{k+kn}{from} \PY{n+nn}{segmentation} \PY{k}{import} \PY{n}{color\PYZus{}position\PYZus{}features}
         
         \PY{c+c1}{\PYZsh{} Load a small segmentation dataset}
         \PY{n}{imgs}\PY{p}{,} \PY{n}{gt\PYZus{}masks} \PY{o}{=} \PY{n}{load\PYZus{}dataset}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Set the parameters for segmentation.}
         \PY{n}{num\PYZus{}segments} \PY{o}{=} \PY{l+m+mi}{2}
         \PY{n}{clustering\PYZus{}fn} \PY{o}{=} \PY{n}{kmeans\PYZus{}fast}
         \PY{n}{feature\PYZus{}fn} \PY{o}{=} \PY{n}{color\PYZus{}position\PYZus{}features}
         \PY{n}{scale} \PY{o}{=} \PY{l+m+mf}{0.5}
         
         \PY{n}{mean\PYZus{}accuracy} \PY{o}{=} \PY{l+m+mf}{0.0}
         
         \PY{n}{segmentations} \PY{o}{=} \PY{p}{[}\PY{p}{]}
         
         \PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{p}{(}\PY{n}{img}\PY{p}{,} \PY{n}{gt\PYZus{}mask}\PY{p}{)} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n+nb}{zip}\PY{p}{(}\PY{n}{imgs}\PY{p}{,} \PY{n}{gt\PYZus{}masks}\PY{p}{)}\PY{p}{)}\PY{p}{:}
             \PY{c+c1}{\PYZsh{} Compute a segmentation for this image}
             \PY{n}{segments} \PY{o}{=} \PY{n}{compute\PYZus{}segmentation}\PY{p}{(}\PY{n}{img}\PY{p}{,} \PY{n}{num\PYZus{}segments}\PY{p}{,}
                                             \PY{n}{clustering\PYZus{}fn}\PY{o}{=}\PY{n}{clustering\PYZus{}fn}\PY{p}{,}
                                             \PY{n}{feature\PYZus{}fn}\PY{o}{=}\PY{n}{feature\PYZus{}fn}\PY{p}{,}
                                             \PY{n}{scale}\PY{o}{=}\PY{n}{scale}\PY{p}{)}
             
             \PY{n}{segmentations}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{segments}\PY{p}{)}
             
             \PY{c+c1}{\PYZsh{} Evaluate segmentation}
             \PY{n}{accuracy} \PY{o}{=} \PY{n}{evaluate\PYZus{}segmentation}\PY{p}{(}\PY{n}{gt\PYZus{}mask}\PY{p}{,} \PY{n}{segments}\PY{p}{)}
             
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Accuracy for image }\PY{l+s+si}{\PYZpc{}d}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZpc{}0.4f}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}}\PY{p}{(}\PY{n}{i}\PY{p}{,} \PY{n}{accuracy}\PY{p}{)}\PY{p}{)}
             \PY{n}{mean\PYZus{}accuracy} \PY{o}{+}\PY{o}{=} \PY{n}{accuracy}
             
         \PY{n}{mean\PYZus{}accuracy} \PY{o}{=} \PY{n}{mean\PYZus{}accuracy} \PY{o}{/} \PY{n+nb}{len}\PY{p}{(}\PY{n}{imgs}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Mean accuracy: }\PY{l+s+si}{\PYZpc{}0.4f}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}} \PY{n}{mean\PYZus{}accuracy}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Accuracy for image 0: 0.8212
Accuracy for image 1: 0.9045
Accuracy for image 2: 0.9832
Accuracy for image 3: 0.6043
Accuracy for image 4: 0.6986
Accuracy for image 5: 0.8733
Accuracy for image 6: 0.5759
Accuracy for image 7: 0.8672
Accuracy for image 8: 0.8996
Accuracy for image 9: 0.9382
Accuracy for image 10: 0.7032
Accuracy for image 11: 0.6050
Accuracy for image 12: 0.5623
Accuracy for image 13: 0.6537
Accuracy for image 14: 0.7745
Accuracy for image 15: 0.5076
Mean accuracy: 0.7483

    \end{Verbatim}

    Include a detailed evaluation of the effect of varying segmentation
parameters (feature transform, clustering method, number of clusters,
resize) on the mean accuracy of foreground-background segmentations on
the provided dataset. You should test a minimum of 10 combinations of
parameters. To present your results, add rows to the table below (you
may delete the first row).

    Note: I changed some values in the existing cells instead of redoing
everything in each step.

\begin{verbatim}
<th>Feature Transform</th>
<th>Clustering Method</th>
<th>Number of segments</th>
<th>Scale</th>
<th>Mean Accuracy</th>
\end{verbatim}

\begin{verbatim}
<tr>
<td>Color</td>
<td>K-Means (Fast)</td>
<td>2</td>
<td>0.5</td>
<td>0.7632</td>
\end{verbatim}

\begin{verbatim}
<td>Color</td>
<td>K-Means (Fast)</td>
<td>3</td>
<td>0.5</td>
<td>0.7920</td>
\end{verbatim}

\begin{verbatim}
<tr>
<td>Color</td>
<td>K-Means (Fast)</td>
<td>5</td>
<td>0.5</td>
<td>0.7667</td>
\end{verbatim}

\begin{verbatim}
<td>Color-Position</td>
<td>K-Means (Fast)</td>
<td>2</td>
<td>0.5</td>
<td>0.7224</td>
\end{verbatim}

\begin{verbatim}
  <tr>
<td>Color-Position</td>
<td>K-Means (Fast)</td>
<td>3</td>
<td>0.5</td>
<td>0.7836</td>
\end{verbatim}

\begin{verbatim}
    <tr>
<td>Color-Position</td>
<td>K-Means (Fast)</td>
<td>5</td>
<td>0.5</td>
<td>0.8004</td>
\end{verbatim}

\begin{verbatim}
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
\end{verbatim}

    Observe your results carefully and try to answer the following question:
1. Based on your quantitative experiments, how do each of the
segmentation parameters affect the quality of the final
foreground-background segmentation? 2. Are some images simply more
difficult to segment correctly than others? If so, what are the
qualities of these images that cause the segmentation algorithms to
perform poorly? 3. Also feel free to point out or discuss any other
interesting observations that you made.

Write your analysis in the cell below.

    \textbf{Your answer here}:

Generally, an increase in the number of segments leads to a higher mean
accuracy. However, this might not always be the case if we put a very
large number, depending on our dataset.

We also notice that images with multiple colors (for instance cats with
colored patches or stripes) are harder to segment. For instance, the
accuracy for images 9 and 15 are lower.

The difference in accuracies from color-position \& color features isn't
very different so we conclude that including the position does not
necessarily help a lot.


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
